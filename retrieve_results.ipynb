{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import seml\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# import seaborn as sns\n",
    "# from matplotlib import pyplot as plt\n",
    "from collections import defaultdict\n",
    "\n",
    "# sns.set_style(\"whitegrid\")\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "# pd.options.mode.chained_assignment = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tune baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seml\n",
    "\n",
    "full_results = seml.get_results('eanet_Be', to_data_frame=True, fields=['config', 'result'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = full_results[['config.dataset_name', \n",
    "                   'config.graphmodel', \n",
    "                   'config.micro_batch', \n",
    "                   'config.mode', \n",
    "                   'config.neighbor_sampling', \n",
    "                        \n",
    "                    # 'config.n_sampling_params.n_nodes',\n",
    "                        \n",
    "                    'config.rw_sampling_params.batch_size',\n",
    "                    'config.rw_sampling_params.walk_length',\n",
    "                   \n",
    "                        \n",
    "                   'result.disk_loading_time', \n",
    "                   'result.graph_preprocess_time',\n",
    "                   'result.train_prep_time', \n",
    "                   'result.infer_prep_time',\n",
    "                   'result.caching_time', \n",
    "                   'result.runtime_train_perEpoch',\n",
    "                   'result.runtime_selfval_perEpoch', \n",
    "                   'result.runtime_partval_perEpoch',\n",
    "                   'result.runtime_pprval_perEpoch', \n",
    "                   'result.gpu_memory',\n",
    "                   'result.best_train_accs_record',\n",
    "                   'result.self_val_accs_record',\n",
    "                   'result.part_val_accs_record',\n",
    "                   'result.ppr_val_accs_record',\n",
    "                   'result.self_test_accs_record',\n",
    "                   'result.part_test_accs_record',\n",
    "                   'result.ppr_test_accs_record', \n",
    "                   'result.self_inference_time_record',\n",
    "                   'result.part_inference_time_record',\n",
    "                   'result.ppr_inference_time_record',\n",
    "                   'result.full_val_accs_record',\n",
    "                   'result.full_test_accs_record',\n",
    "                   'result.full_inference_time_record',\n",
    "                   'stats.self.max_memory_bytes', \n",
    "                   'stats.children.max_memory_bytes',]]\n",
    "\n",
    "max_memory = results['stats.self.max_memory_bytes'] + results['stats.children.max_memory_bytes']\n",
    "results['result.max_memory'] = max_memory\n",
    "results = results.drop(columns=['stats.self.max_memory_bytes', 'stats.children.max_memory_bytes'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in results.keys():\n",
    "    for i in range(len(results)):\n",
    "        if isinstance(results[k].iloc[i], list):\n",
    "            if len(results[k].iloc[i]) == 1:\n",
    "                results.loc[i, k] = float(results[k].iloc[i][0])\n",
    "            else:\n",
    "                results.loc[i, k] = str(results[k].iloc[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = ['result.disk_loading_time', \n",
    "                   'result.graph_preprocess_time',\n",
    "                   'result.train_prep_time', \n",
    "                   'result.infer_prep_time',\n",
    "                   'result.caching_time', \n",
    "                   'result.runtime_train_perEpoch',\n",
    "                   'result.runtime_selfval_perEpoch', \n",
    "                   'result.runtime_partval_perEpoch',\n",
    "                   'result.runtime_pprval_perEpoch', \n",
    "                   'result.gpu_memory',\n",
    "                   'result.best_train_accs_record',\n",
    "                   'result.self_val_accs_record',\n",
    "                   'result.part_val_accs_record',\n",
    "                   'result.ppr_val_accs_record',\n",
    "                   'result.self_test_accs_record',\n",
    "                   'result.part_test_accs_record',\n",
    "                   'result.ppr_test_accs_record', \n",
    "                   'result.self_inference_time_record',\n",
    "                   'result.part_inference_time_record',\n",
    "                   'result.ppr_inference_time_record',\n",
    "                   'result.full_val_accs_record',\n",
    "                   'result.full_test_accs_record',\n",
    "                   'result.full_inference_time_record',\n",
    "                   'result.max_memory']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grp_res = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = results.groupby(['config.rw_sampling_params.batch_size',\n",
    "                    'config.rw_sampling_params.walk_length',])\n",
    "for k in keys:\n",
    "    grp_res[k] = g[k].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grp_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# papers100M full infer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "term = 'ppr96_full'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = defaultdict(list)\n",
    "for i in range(3):\n",
    "    results = seml.get_results(f'{term}{i}', to_data_frame=True)\n",
    "    for key, val in results.items():\n",
    "        if 'result' in key:\n",
    "            stats[key] += val[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, val in stats.items():\n",
    "    print(f'{key}: ({np.mean(val)}, {np.std(val)})')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = seml.get_results('inferl_all', to_data_frame=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "results = results[['config.dataset_name', 'config.graphmodel', 'config.mode', 'config.neighbor_sampling', 'config.num_batches', \n",
    "                   'config.ppr_params.neighbor_topk', 'config.ppr_params.primes_per_batch', \n",
    "                   'result.val_prep_time', 'result.infer_prep_time', 'result.caching_time', \n",
    "        'result.gpu_memory', 'result.max_memory', 'result.self_val_accs_stats', \n",
    "        'result.self_val_f1s_stats', 'result.self_test_accs_stats', 'result.self_test_f1s_stats', \n",
    "        'result.self_inference_time_stats', 'result.numbatch_self_val_stats', 'result.numbatch_self_test_stats', ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.to_excel('data.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# full infer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# infertime = []\n",
    "# testacc = []\n",
    "# testf1 = []\n",
    "# valacc = []\n",
    "# valf1 = []\n",
    "\n",
    "\n",
    "results = seml.get_results(f'sage_reddit_full', to_data_frame=True)\n",
    "results = pd.DataFrame(results, columns= ['config.num_batches',\n",
    "                                          'result.val_prep_time',\n",
    "                                          'result.infer_prep_time',\n",
    "                                          'result.caching_time',\n",
    "                                          'result.gpu_memory',\n",
    "                                          'result.max_memory',\n",
    "                                          'result.full_val_accs_stats',\n",
    "                                          'result.full_val_f1s_stats',\n",
    "                                          'result.full_test_accs_stats',\n",
    "                                          'result.full_test_f1s_stats',\n",
    "                                          'result.full_inference_time_stats'])\n",
    "# infertime.append(results['result.full_inference_time_stats'].item()[0])\n",
    "# testacc.append(results['result.full_test_accs_stats'].item()[0])\n",
    "# testf1.append(results['result.full_test_f1s_stats'].item()[0])\n",
    "# valacc.append(results['result.full_val_accs_stats'].item()[0])\n",
    "# valf1.append(results['result.full_val_f1s_stats'].item()[0])\n",
    "# results.to_excel('data.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "infertime = np.array(infertime)\n",
    "infertime.mean(), infertime.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testacc = np.array(testacc)\n",
    "testacc.mean(), testacc.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testf1 = np.array(testf1)\n",
    "testf1.mean(), testf1.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valacc = np.array(valacc)\n",
    "valacc.mean(), valacc.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valf1 = np.array(valf1)\n",
    "valf1.mean(), valf1.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_results = seml.get_results('kdd_main_gcn_prod_rw', to_data_frame=True, fields=['config', 'result', 'stats'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_table(model, dataset, mode, micro_batch):\n",
    "    results = full_results[np.array(full_results['config.mode'] == mode) & \n",
    "        np.array(full_results['config.micro_batch'] == micro_batch) & \n",
    "        np.array(full_results['config.graphmodel'] == model) & \n",
    "        np.array(full_results['config.dataset_name'] == dataset)]\n",
    "    \n",
    "    # return results\n",
    "    print(len(results))\n",
    "    assert len(results) == 10\n",
    "    # results = results.iloc[-5:]\n",
    "    \n",
    "    results = results[['config.dataset_name', \n",
    "                   'config.graphmodel', \n",
    "                   'config.micro_batch', \n",
    "                   'config.mode', \n",
    "                   'config.neighbor_sampling', \n",
    "                   \n",
    "                   'result.disk_loading_time', \n",
    "                   'result.graph_preprocess_time',\n",
    "                   'result.train_prep_time', \n",
    "                   'result.infer_prep_time',\n",
    "                   'result.caching_time', \n",
    "                   'result.runtime_train_perEpoch',\n",
    "                   'result.runtime_selfval_perEpoch', \n",
    "                   'result.runtime_partval_perEpoch',\n",
    "                   'result.runtime_pprval_perEpoch', \n",
    "                   'result.gpu_memory',\n",
    "                   'result.best_train_accs_record',\n",
    "                   'result.self_val_accs_record',\n",
    "                   'result.part_val_accs_record',\n",
    "                   'result.ppr_val_accs_record',\n",
    "                   'result.self_test_accs_record',\n",
    "                   'result.part_test_accs_record',\n",
    "                   'result.ppr_test_accs_record', \n",
    "                   'result.self_inference_time_record',\n",
    "                   'result.part_inference_time_record',\n",
    "                   'result.ppr_inference_time_record',\n",
    "                   'result.full_val_accs_record',\n",
    "                   'result.full_test_accs_record',\n",
    "                   'result.full_inference_time_record',\n",
    "                   'stats.self.max_memory_bytes', \n",
    "                   'stats.children.max_memory_bytes',]]\n",
    "    \n",
    "    results['result.max_memory'] = results['stats.self.max_memory_bytes'] + results['stats.children.max_memory_bytes']\n",
    "    results = results.drop(columns=['stats.self.max_memory_bytes', 'stats.children.max_memory_bytes'])\n",
    "    \n",
    "    aggr_res = {}\n",
    "\n",
    "    for key in results.keys():\n",
    "        if 'config' in key:\n",
    "            continue\n",
    "        if isinstance(results[key].iloc[0], list):\n",
    "            arr = np.array([l[0] for l in results[key]])\n",
    "            name = '_'.join(key.split('.')[-1].split('_')[:-1])\n",
    "            aggr_res[name + '_mean'] = [arr.mean()]\n",
    "            aggr_res[name + '_std'] = [arr.std()]\n",
    "        else:\n",
    "            arr = results[key]\n",
    "            aggr_res[key.split('.')[-1]] = [np.mean(arr)]\n",
    "            \n",
    "    if mode in ['ppr', 'part']:\n",
    "        for split in ['val', 'test']:\n",
    "            for stat in ['mean', 'std']:\n",
    "                aggr_res[f'{mode}_{split}_accs_{stat}'] = aggr_res[f'self_{split}_accs_{stat}']\n",
    "                \n",
    "    return aggr_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = None\n",
    "# for mode in ['part', 'ppr', 'clustergcn']:\n",
    "res = get_table('gcn', 'products', 'rw_sampling', 1)\n",
    "if df is None:\n",
    "    df = pd.DataFrame.from_dict(res)\n",
    "else:\n",
    "    df = df.append(pd.DataFrame.from_dict(res))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_results = seml.get_results('kdd_main', to_data_frame=True, fields=['config', 'result', 'stats'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modes = ['part', 'ppr', 'clustergcn', 'rw_sampling', 'n_sampling', 'ladies']\n",
    "modes = ['part', 'ppr', 'clustergcn',]\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "namedict = {'part': 'partition', 'ppr': 'PPR', 'clustergcn': 'clsgcn', 'rw_sampling': 'RW', 'n_sampling': 'NS', 'ladies': 'LD', \n",
    "           'arxiv': 'Arch', 'products': 'Prod', 'reddit': 'Reddit'}\n",
    "\n",
    "model = 'sage'\n",
    "dataset = 'reddit'\n",
    "\n",
    "for mode in modes:\n",
    "\n",
    "    results = full_results[np.array(full_results['config.mode'] == mode) & \n",
    "            np.array(full_results['config.micro_batch'] == 2) & \n",
    "            np.array(full_results['config.graphmodel'] == model) & \n",
    "            np.array(full_results['config.dataset_name'] == dataset)]\n",
    "    \n",
    "    assert len(results) == 10, f'{mode} hasnt 10 runs'\n",
    "    # results = results.iloc[-10:]\n",
    "    # results['config.n_sampling_params.n_nodes'] = results['config.n_sampling_params.n_nodes'].astype(str)\n",
    "    # results[results['config.n_sampling_params.n_nodes'] == '[5, 5, 5]']\n",
    "    results = results['result.curves']\n",
    "    \n",
    "    df = defaultdict(list)\n",
    "    for i in range(10):\n",
    "        line = results.iloc[i][0]\n",
    "        for k, v in line.items():\n",
    "            df[k] += v\n",
    "        df['num_run'] += [i] * len(v)\n",
    "    \n",
    "    df = pd.DataFrame.from_dict(df)\n",
    "    df.to_csv(f'{namedict[dataset]}_{model.upper()}_{namedict[mode]}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
